{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/home/maria/Documents/pybullet-robot-envs/pybullet_robot_envs/envs/panda_envs\n",
      "current_dir=/home/maria/Documents/pybullet-robot-envs/pybullet_robot_envs/envs/panda_envs\n",
      "Box(3,)\n",
      "Box(31,)\n",
      "reward -0.3489662942718912\n",
      "reward -0.33935376105368487\n",
      "reward -0.33508681339089597\n",
      "reward -0.3332890912473407\n",
      "reward -0.3312289445175904\n",
      "reward -0.33034226464086924\n",
      "reward -0.3317178676167966\n",
      "reward -0.3329965157179698\n",
      "reward -0.3354460723139667\n",
      "reward -0.3409517679303787\n",
      "reward -0.34762487532742536\n",
      "reward -0.351424600913896\n",
      "reward -0.34900155824466045\n",
      "reward -0.3462871059504774\n",
      "reward -0.34530527321199905\n",
      "reward -0.3421730774828638\n",
      "reward -0.3445272886660802\n",
      "reward -0.3457840744784656\n",
      "reward -0.34603127203145384\n",
      "reward -0.3422893349063951\n",
      "reward -0.3416386115225044\n",
      "reward -0.3417007024678523\n",
      "reward -0.34217349705686073\n",
      "reward -0.34641566183270717\n",
      "reward -0.345238301114949\n",
      "reward -0.3424987077628939\n",
      "reward -0.3377939973120667\n",
      "reward -0.3347571813687899\n",
      "reward -0.33203706573458874\n",
      "reward -0.32854667968816464\n",
      "reward -0.32360793145098965\n",
      "reward -0.3199339073749657\n",
      "reward -0.3126695884941221\n",
      "reward -0.3042920685355944\n",
      "reward -0.29918415994804126\n",
      "reward -0.2965364827618974\n",
      "reward -0.29151895102948167\n",
      "reward -0.2903249007415277\n",
      "reward -0.2963208657204093\n",
      "reward -0.2946763450511978\n",
      "reward -0.2950460806126739\n",
      "reward -0.30286885853750034\n",
      "reward -0.30829060788316837\n",
      "reward -0.3083284731039646\n",
      "reward -0.3002038852550419\n",
      "reward -0.30065190437371647\n",
      "reward -0.3062455628137553\n",
      "reward -0.31189591110553067\n",
      "reward -0.318176253173938\n",
      "reward -0.3242887736304245\n",
      "reward -0.3281916254554983\n",
      "reward -0.3271048609226362\n",
      "reward -0.3222881031636435\n",
      "reward -0.3192699324629133\n",
      "reward -0.3129264670420031\n",
      "reward -0.3062689197892003\n",
      "reward -0.29955481731401723\n",
      "reward -0.2938271704662835\n",
      "reward -0.2891339667504067\n",
      "reward -0.2904538060793625\n",
      "reward -0.29437262949106263\n",
      "reward -0.29958942179443515\n",
      "reward -0.29648949730373525\n",
      "reward -0.2877487692382947\n",
      "reward -0.2810915971401894\n",
      "reward -0.28116902883975564\n",
      "reward -0.28294844854118356\n",
      "reward -0.28411540198032365\n",
      "reward -0.2867319783276456\n",
      "reward -0.2866693346218795\n",
      "reward -0.27959401264514105\n",
      "reward -0.2706044569657845\n",
      "reward -0.26343329822622646\n",
      "reward -0.2570258328594681\n",
      "reward -0.25577766762180326\n",
      "reward -0.25658403416801157\n",
      "reward -0.25177020883594814\n",
      "reward -0.24605844040262112\n",
      "reward -0.24615246274155878\n",
      "reward -0.24643013183348664\n",
      "reward -0.2479698293242611\n",
      "reward -0.2492394872075324\n",
      "reward -0.2443439479532454\n",
      "reward -0.24155436933439225\n",
      "reward -0.23989551792243288\n",
      "reward -0.23713789463996773\n",
      "reward -0.23040851544284224\n",
      "reward -0.22053157257057363\n",
      "reward -0.21666060699704778\n",
      "reward -0.22298018803847755\n",
      "reward -0.23154080058414683\n",
      "reward -0.24027830588529459\n",
      "reward -0.24733806493474927\n",
      "reward -0.25253324607340333\n",
      "reward -0.25642302433900976\n",
      "reward -0.26460774512528984\n",
      "reward -0.26829897470374425\n",
      "reward -0.26200017235440337\n",
      "reward -0.25882216447881234\n",
      "reward -0.2584017945617509\n",
      "reward -0.2605421711968752\n",
      "reward -0.2688079377364573\n",
      "reward -0.27290415547114816\n",
      "reward -0.2748412217376734\n",
      "reward -0.2757332296766844\n",
      "reward -0.27770482709117317\n",
      "reward -0.2767802192134594\n",
      "reward -0.27307403014499354\n",
      "reward -0.26823363655474686\n",
      "reward -0.26647205390275075\n",
      "reward -0.26596248057262584\n",
      "reward -0.2635387172400283\n",
      "reward -0.2645037000847788\n",
      "reward -0.26580320346469516\n",
      "reward -0.26885128387520235\n",
      "reward -0.27363637562144627\n",
      "reward -0.2748366171028521\n",
      "reward -0.2751069070298626\n",
      "reward -0.27418422198502235\n",
      "reward -0.26857143057338634\n",
      "reward -0.2615648945613758\n",
      "reward -0.25776887193362424\n",
      "reward -0.26099811361905007\n",
      "reward -0.2646579812881256\n",
      "reward -0.26464834749769617\n",
      "reward -0.265432180380219\n",
      "reward -0.2667025318539681\n",
      "reward -0.27047631206313727\n",
      "reward -0.2775040711326399\n",
      "reward -0.28107498279063564\n",
      "reward -0.2816468870227223\n",
      "reward -0.27761436397620337\n",
      "reward -0.2699993459819426\n",
      "reward -0.2660780264690016\n",
      "reward -0.26196176647577174\n",
      "reward -0.2559050699908525\n",
      "reward -0.2542644221541079\n",
      "reward -0.25791851397984566\n",
      "reward -0.26205538574735204\n",
      "reward -0.2619258395651621\n",
      "reward -0.25991889433476323\n",
      "reward -0.2588617639820447\n",
      "reward -0.2578591995098155\n",
      "reward -0.26095960693736847\n",
      "reward -0.2592776539166021\n",
      "reward -0.2489176555655109\n",
      "reward -0.23799370716690904\n",
      "reward -0.23297082183532888\n",
      "reward -0.23685006644819218\n",
      "reward -0.23645806570573796\n",
      "reward -0.23457150577172775\n",
      "reward -0.2325601420156641\n",
      "reward -0.23425033448636545\n",
      "reward -0.23358032300657774\n",
      "reward -0.23244612630285513\n",
      "reward -0.23022801132934567\n",
      "reward -0.2233953545192702\n",
      "reward -0.2215003533377011\n",
      "reward -0.22132744379844918\n",
      "reward -0.21959467844944278\n",
      "reward -0.22241038943274413\n",
      "reward -0.22142589637757557\n",
      "reward -0.21804915503551764\n",
      "reward -0.21872538002051295\n",
      "reward -0.22386423230956173\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1a68d0ecc7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print('action',action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/pybullet-robot-envs/pybullet_robot_envs/envs/icub_envs/icub_reach_gym_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mrealOrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrealPos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrealOrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/pybullet-robot-envs/pybullet_robot_envs/envs/icub_envs/icub_reach_gym_env.py\u001b[0m in \u001b[0;36mstep2\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepSimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_termination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#https://github.com/robotology-playground/pybullet-robot-envs\n",
    "import gym\n",
    "env = gym.make('pybullet_robot_envs:iCubReach-v0')\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "\n",
    "num_episodes=10\n",
    "for episode in range(num_episodes):\n",
    "    state=env.reset()\n",
    "    for step in range(1000):\n",
    "        action=env.action_space.sample()\n",
    "        new_state,reward,done_flag,info=env.step(action)\n",
    "        print('reward',reward)\n",
    "        #print('action',action)\n",
    "        env.render(mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
